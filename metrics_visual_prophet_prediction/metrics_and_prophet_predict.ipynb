{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce1cc82",
   "metadata": {},
   "source": [
    "# Минипроект ч.2\n",
    "# Исследование данных. Динамика метрик. Прогноз временных рядов fbprophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13226973",
   "metadata": {},
   "source": [
    "## Описание данных\n",
    "#### Датасет E-Commerce Data  \n",
    "**Источник** https://www.kaggle.com/datasets/carrie1/ecommerce-data  \n",
    "**Описание:** 'This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.'\n",
    "\n",
    "Имеются следующие данные о транзакциях в период с 01.12.2010 по 12.09.2011:\n",
    "\n",
    "* InvoiceNo — номер транзакции  \n",
    "* StockCode — код товара  \n",
    "* Description — описание товара  \n",
    "* Quantity — количество единиц товара, добавленных в заказ  \n",
    "* InvoiceDate — дата транзакции   \n",
    "* UnitPrice — цена за единицу товара  \n",
    "* CustomerID — id клиента  \n",
    "* Country — страна, где проживает клиент  \n",
    "  \n",
    "Данные содержат в себе записи как об успешных транзакциях, так и об отмененных. В данных встречаются строки с Description 'Manual', которые включают данные об удаленных из чека позициях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca44bc",
   "metadata": {},
   "source": [
    "## Задачи минипроекта:\n",
    "\n",
    "1. Визуализировать основные метрики в динамике за год (выручка, средний чек, возвраты товара, новые\\повторные покупатели)\n",
    "2. Спогнозировать выручку с помощью fbprophet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7026f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from operator import attrgetter\n",
    "import matplotlib.colors as mcolors\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515993b6",
   "metadata": {},
   "source": [
    "### Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7567a265",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/archive.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g9/bw4b5fds4b14388m7_2rsnlw0000gn/T/ipykernel_27896/1278852568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/archive.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'windows-1251'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# ZIP Compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_BytesZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# TextIOBase, TextIOWrapper, mmap]]]\"; expected \"Union[Union[str,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# _PathLike[str]], IO[bytes]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_zip\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/archive.zip'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/archive.zip', encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041289ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f288e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80515e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14c6e8",
   "metadata": {},
   "source": [
    "В данных есть дубликаты, удалим эти строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd07375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1022e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018ecf4",
   "metadata": {},
   "source": [
    "Также в данных есть пропущенные значения. Так как это значения CustomerID, лучше их удалить: одна из наших целей - разбиение покупателей на сегменты и строки без CustomerID для нас бесполезны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc342212",
   "metadata": {},
   "source": [
    "Приведем неверно распознанные данные к нужному типу - дату в datetime, а CustomerID в object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e80d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652f4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CustomerID_ob'] = df['CustomerID'].astype('object').apply(lambda x: str(x).replace('.0', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f435f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.InvoiceDate = pd.to_datetime(df.InvoiceDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c24a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CustomerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a61ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf1d22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678dde8",
   "metadata": {},
   "source": [
    "Нам известно, что часть транзакций имеют пометку Manual, и содержат данные об удаленных из чека позициях. Удалим их из нашего датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc71b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Description != 'Manual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bcc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a2a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b7c91",
   "metadata": {},
   "source": [
    "Проверим количественные данные на выбросы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c778e36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ca74e",
   "metadata": {},
   "source": [
    "Мы видим, что в столбце Quantity есть очень большие значения, причем максимум и минимум равны. Очень похоже на ошибочные транзакции, впоследствии отмененные. Проверим, может быть, их несколько. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a83fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Quantity.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50694d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Quantity in (-80995, -74215, -9360, -3114, 12540, 4800, 74215, 80995)').sort_values('CustomerID_ob')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7606615",
   "metadata": {},
   "source": [
    "Действительно, 4 самых больших значения Quantity по сути являются сразу же отмененными заказами (возможно, как раз из-за ошибки в количестве). На мой взгляд, для дальнейшего анализа не нужно принимать их во внимание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df['Quantity'].isin([-80995, -74215, 74215, 80995])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbac947",
   "metadata": {},
   "source": [
    "Теперь обратимся к выбросам столбца UnitPrice. Посмотрим на самые дорогие товары. Мы видим, что это в основном доставки(POSTAGE) и комиссии. Как мы видим, у них есть отличие от товаров - в поле StockCode указаны только буквенные обозначения. При анализе метрик, таких как средний чек, они будут нам только мешать. Удалим эти позиции. А также не будем учитывать транзакции с ценой товара равной нулю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('UnitPrice', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd62124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['StockCode'].str.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.UnitPrice != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965e5a3",
   "metadata": {},
   "source": [
    "Описание итогового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99259f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue'] = df['Quantity'] * df['UnitPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2346ac",
   "metadata": {},
   "source": [
    "Мы добавили новый столбец с суммой заказа. Это наш датафрейм с очищенными данными.   \n",
    "Для дальнейшего исследования пока исключим отмененнные заказы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7865788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchases = df[(df.Quantity >0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ca8dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_purchases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90feeff8",
   "metadata": {},
   "source": [
    "Обратимся к столбцу Country. Мы знаем, что в датасет включены продажи по разным странам. Посмотрим на сумму покупок, количество уникальных заказов и покупателей с точки зрения географии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec87ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_purchases.groupby('Country', as_index=False)\\\n",
    "            .agg({'Revenue':'sum', \n",
    "                   'InvoiceNo':'nunique', \n",
    "                    'CustomerID_ob':'nunique'})\\\n",
    "            .rename(columns={'Revenue':'total_revenue', \n",
    "                   'InvoiceNo':'unique_orders', \n",
    "                    'CustomerID_ob':'unique_customers'})\\\n",
    "            .sort_values('unique_customers', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e2fe9",
   "metadata": {},
   "source": [
    "Большая часть данных в датасете относятся к United Kingdom. Вероятно, это внутренний рынок, а на экспорт идет значительно меньше продукции. Посмотрим на соотношение выручки, заказов и покупателей на внутреннем и внешнем рынках. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a49d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchases['market_group'] = df['Country'].apply(lambda x: \n",
    "                                                   'internal_market' if x == 'United Kingdom' \n",
    "                                                   else 'foreign_market')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391dfa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchases.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea2bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_purchases.groupby('market_group', as_index=False)\\\n",
    "            .agg({'Revenue':'sum', \n",
    "                   'InvoiceNo':'nunique', \n",
    "                    'CustomerID_ob':'nunique'})\\\n",
    "            .rename(columns={'Revenue':'total_revenue', \n",
    "                   'InvoiceNo':'unique_orders', \n",
    "                    'CustomerID_ob':'unique_customers'})\\\n",
    "            .sort_values('unique_customers', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf7778",
   "metadata": {},
   "source": [
    "Для наших задач - изучения Retention и сегментации пользователей - очевидно интереснее будет проанализировать данные внутреннего рынка. \n",
    "Отберем их в финальный датафрейм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = df_purchases[df_purchases.Country == 'United Kingdom'][['InvoiceDate',\n",
    "                                    'CustomerID_ob', \n",
    "                                    'InvoiceNo', \n",
    "                                    'StockCode', \n",
    "                                    'Description', \n",
    "                                    'Quantity',\n",
    "                                   'UnitPrice',\n",
    "                                   'Revenue']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1616a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fin_df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1d53f",
   "metadata": {},
   "source": [
    "## Динамика метрик в течение года"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53662ed",
   "metadata": {},
   "source": [
    "Основные метрики - Средний чек (AOV), общий объём оборота товаров GMV (Gross Merchandise Value), процент возвратов, repeat rate(доля повторных покупателей), соотношение новых и старых пользователей(Old vs New)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770e41f",
   "metadata": {},
   "source": [
    "Сформируем таблицу для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e23bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df['orders_date'] = pd.DatetimeIndex(fin_df.InvoiceDate).date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day = fin_df.groupby('orders_date').agg(customers_count=('CustomerID_ob', 'nunique'),\n",
    "                                 orders_count=('InvoiceNo', 'nunique'),\n",
    "                                 total_revenue=('Revenue', 'sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc12867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['avg_check'] = df_per_day.total_revenue / df_per_day.orders_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['ARPU'] = df_per_day.total_revenue / df_per_day.customers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['total_revenue_roll'] = df_per_day.total_revenue.rolling(window=5, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d14eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df['first_order_date'] = pd.DatetimeIndex(fin_df.groupby('CustomerID_ob').\n",
    "                                                InvoiceDate.transform('min')).date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['new_customers'] = fin_df.groupby('first_order_date').CustomerID_ob.nunique().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d07710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day = df_per_day.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ea060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['old_customers'] = df_per_day.customers_count - df_per_day.new_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c082fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['repeat_rate'] = df_per_day.old_customers / df_per_day.customers_count * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df4ac6",
   "metadata": {},
   "source": [
    "Вспомним про отмененные заказы, создадим отдельный датафрейм и сджойним его с основным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancells_df = df[(df.Quantity <0)& (df.Country == 'United Kingdom')][['InvoiceDate',\n",
    "                                    'CustomerID_ob', \n",
    "                                    'InvoiceNo', \n",
    "                                    'StockCode', \n",
    "                                    'Description', \n",
    "                                    'Quantity',\n",
    "                                   'UnitPrice',\n",
    "                                   'Revenue']].reset_index(drop=True)\n",
    "cancells_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancells_df['cancell_date'] = pd.DatetimeIndex(cancells_df.InvoiceDate).date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancells_df_per_day = cancells_df.groupby('cancell_date').agg(\n",
    "                                 customers_cancellation_count=('CustomerID_ob', 'nunique'),\n",
    "                                 orders_cancellation_count=('InvoiceNo', 'nunique'),\n",
    "                                 total_cancellation_sum=('Revenue', 'sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2607dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day = df_per_day.merge(cancells_df_per_day, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae9d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['cancellation_rate'] = df_per_day.customers_cancellation_count / df_per_day.customers_count *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day = df_per_day.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['orders_date'] = pd.DatetimeIndex(df_per_day['orders_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day = df_per_day.set_index(df_per_day.orders_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day['avg_check_canc'] = df_per_day.total_cancellation_sum / df_per_day.orders_cancellation_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f9a262",
   "metadata": {},
   "source": [
    "Итоговый датафрейм для анализа динамики показателей. Создадим несколько интерактивных визуализаций по основным метрикам, используя Plotly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c830dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_day.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a85441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_per_day.resample('w').mean(),  \n",
    "             y=['total_revenue', 'total_cancellation_sum'],\n",
    "            title='Gross Merchandise Value VS Loss from order cancellation per weeks')\n",
    "fig.update_layout(\n",
    "    margin=dict(\n",
    "    autoexpand=True\n",
    "    ),\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ),\n",
    "    legend_title_text='',\n",
    "    yaxis=dict(\n",
    "        title='', showticklabels=False\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        dtick=\"M1\",\n",
    "    tickformat=\"%b\\n%Y\",\n",
    "        title='Date of order'\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    plot_bgcolor='white', \n",
    "    uniformtext_minsize=8,\n",
    "    uniformtext_mode='hide')\n",
    "newnames = {'total_revenue': \"Gross Merchandise Value, $\", \n",
    "            'total_cancellation_sum': \"Loss from order cancellation, $\"}\n",
    "fig.for_each_trace(lambda t: t.update(\n",
    "    name = newnames[t.name],\n",
    "    legendgroup = newnames[t.name],\n",
    "    hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])))\n",
    "fig.show('notebook')\n",
    "fig.write_html('notebook.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_per_day.resample('w').mean(),  y=['avg_check', 'avg_check_canc'], \n",
    "            title='Average Order Value VS Average Cancelled Order Value per weeks')\n",
    "fig.update_layout(margin=dict(\n",
    "        autoexpand=True\n",
    "    ),\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ),\n",
    "    legend_title_text='',\n",
    "    yaxis=dict(\n",
    "        title='', showticklabels=False\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        dtick=\"M1\",\n",
    "    tickformat=\"%b\\n%Y\",\n",
    "        title='Date of order'\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    plot_bgcolor='white', \n",
    "    uniformtext_minsize=8,\n",
    "                  uniformtext_mode='hide')\n",
    "newnames = {'avg_check': \"Average Order Value, $\", 'avg_check_canc': \"Average Cancelled Order Value, $\"}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n",
    "fig.show('notebook')\n",
    "fig.write_html('notebook.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfd7fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = px.bar(df_per_day.resample('m').sum(),  \n",
    "             y=['new_customers','old_customers'], \n",
    "            text_auto=True, \n",
    "             title=\"New customers VS old customers\")\n",
    "fig.update_layout(margin=dict(\n",
    "        autoexpand=True),\n",
    "    showlegend=True, \n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ),\n",
    "    legend_title_text='',\n",
    "    yaxis=dict(\n",
    "        title='Number of customers',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14, visible=True, showticklabels=False\n",
    "    ), \n",
    "    xaxis=dict(\n",
    "        dtick=\"M1\",\n",
    "    tickformat=\"%b\\n%Y\",\n",
    "        title='Order\\'s month'\n",
    "    ),\n",
    "                  \n",
    "    plot_bgcolor='white', \n",
    "    uniformtext_minsize=8,\n",
    "                  uniformtext_mode='hide',\n",
    "    title_font_color=\"black\")\n",
    "fig.update_traces(textposition='outside')\n",
    "newnames = {'new_customers': \"New customers\", 'old_customers': \"Old customers\"}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n",
    "fig.show('notebook')\n",
    "fig.write_html('notebook.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233dc2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.line(df_per_day.resample('w').mean(),  y=['repeat_rate', \n",
    "                                                   'cancellation_rate'], \n",
    "              markers=True, line_shape='spline', title='Percent of reodering and refusing customers')\n",
    "fig.update_layout(margin=dict(\n",
    "        autoexpand=True),\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0.01\n",
    "    ),\n",
    "    legend_title_text='',\n",
    "    yaxis=dict(\n",
    "        title='Percentage',\n",
    "        titlefont_size=14,\n",
    "        tickfont_size=14, visible=True, showticklabels=True\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        dtick=\"M1\",\n",
    "    tickformat=\"%b\\n%Y\",\n",
    "        title='Date of order'\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    plot_bgcolor='white', \n",
    "    uniformtext_minsize=8,\n",
    "    uniformtext_mode='hide')\n",
    "newnames = {'repeat_rate': \"Percent of repeat customers\", \n",
    "            'cancellation_rate': \"Percent of customers with cancelled orders\"}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n",
    "fig.show('notebook')\n",
    "fig.write_html('notebook.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9cb31d",
   "metadata": {},
   "source": [
    "В целом, дела у магазина идут хорошо - оборот увеличивается, причем в основном за счет увеличения процента повторных покупателей. Рост особенно выражен в последние 3 месяца, начиная с сентября. (Помним, что данные только за часть последнего месяца года, так что эти данные не принимаем во внимание).  \n",
    "\n",
    "На что, возможно, стоило бы обратить внимание - на увеличение среднего чека (он тоже растет, но не так уверенно) и привлечение новых клиентов (в течение года их число скорее снижается)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab9ae0",
   "metadata": {},
   "source": [
    "\n",
    "## Прогноз Gross Merchandise Value с fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import holidays\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07163fe",
   "metadata": {},
   "source": [
    "Подготовим датафрейм для прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = df_per_day[['orders_date', 'total_revenue_roll']]\\\n",
    "            .loc[df_per_day['orders_date'] > '2010-01-01']\\\n",
    "            .reset_index(drop=True)\\\n",
    "            .rename({'orders_date':'ds', 'total_revenue_roll':'y'}, axis ='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60281c05",
   "metadata": {},
   "source": [
    "Импортируем праздники "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e58072",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_dict = holidays.UK(years=(2010, 2011, 2012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays = pd.DataFrame.from_dict(holidays_dict, orient='index') \\\n",
    "    .reset_index().rename({'index':'ds', 0:'holiday'}, axis ='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c1042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays['ds'] = pd.to_datetime(df_holidays.ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83785f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_holidays = df_holidays.sort_values(by=['ds']).reset_index(drop=True)\n",
    "df_holidays.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c2af7",
   "metadata": {},
   "source": [
    "Определим тестовую выборку из датафрейма - последние 30 дней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6983ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = 30\n",
    "train_df = df_pr[:-predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a269f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42867e56",
   "metadata": {},
   "source": [
    "Настроим prophet - с учетом праздников, недельной и годовой сезонности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ee541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Prophet(holidays=df_holidays, \n",
    "            daily_seasonality=False, \n",
    "            weekly_seasonality=True, \n",
    "            yearly_seasonality=True,\n",
    "           changepoint_prior_scale=0.02)\n",
    "m.add_country_holidays(country_name='UK')\n",
    "m.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6040e33",
   "metadata": {},
   "source": [
    "Предсказываем 30 дней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7427849",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=predictions)\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b3d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf1870",
   "metadata": {},
   "source": [
    "Посмотрим на результат на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1638c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "plot_plotly(m, forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97647fa4",
   "metadata": {},
   "source": [
    "Также мы можем посмотреть на сезонность данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae69ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_components_plotly(m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рисуем график с границами прогноза\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "iplot([\n",
    "    go.Scatter(x=df_pr['ds'], y=df_pr['y'], name='fact'),\n",
    "    go.Scatter(x=forecast['ds'], y=forecast['yhat'], name='prediction'),\n",
    "    go.Scatter(x=forecast['ds'], y=forecast['yhat_upper'], fill='tonexty', mode='none', name='upper'),\n",
    "    go.Scatter(x=forecast['ds'], y=forecast['yhat_lower'], fill='tonexty', mode='none', name='lower'),\n",
    "    go.Scatter(x=forecast['ds'], y=forecast['trend'], name='trend')\n",
    "])\n",
    "fig.write_html('notebook.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11294d",
   "metadata": {},
   "source": [
    "Проверим качество прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_df = forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(df_pr.set_index('ds'))\n",
    "cmp_df['e'] = cmp_df['y'] - cmp_df['yhat']\n",
    "cmp_df['p'] = 100*cmp_df['e']/cmp_df['y']\n",
    "print('MAPE (средняя абсолютная ошибка в процентах) – ', np.mean(abs(cmp_df[-predictions:]['p'])),'%')\n",
    "print('MAE (средняя абсолютная ошибка) – ', np.mean(abs(cmp_df[-predictions:]['e'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e3349",
   "metadata": {},
   "source": [
    "Рассчитаем прогноз на полный период (например, год) с теми же параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac427e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_days = 365\n",
    "final_train_df = df_pr\n",
    "f = Prophet(holidays=df_holidays, \n",
    "            daily_seasonality=False, \n",
    "            weekly_seasonality=True, \n",
    "            yearly_seasonality=False,\n",
    "           n_changepoints=20)\n",
    "f.add_country_holidays(country_name='UK')\n",
    "f.fit(final_train_df)\n",
    "final_future = f.make_future_dataframe(periods=prediction_days)\n",
    "final_forecast = f.predict(final_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74163ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plot(final_forecast);\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e34b55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Рисуем график с границами прогноза на полном периоде\n",
    "iplot([\n",
    "    go.Scatter(x=df_pr['ds'], y=df_pr['y'], name='fact'),\n",
    "    go.Scatter(x=final_forecast['ds'], y=final_forecast['yhat'], name='yhat'),\n",
    "    go.Scatter(x=final_forecast['ds'], y=final_forecast['yhat_upper'], fill='tonexty', mode='none', name='upper'),\n",
    "    go.Scatter(x=final_forecast['ds'], y=final_forecast['yhat_lower'], fill='tonexty', mode='none', name='lower'),\n",
    "    go.Scatter(x=final_forecast['ds'], y=final_forecast['trend'], name='trend')\n",
    "])\n",
    "fig.write_html('notebook.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcb9b6",
   "metadata": {},
   "source": [
    "Также prophet позволяет нам определить точки изменения - это точки даты и времени, в которых временные ряды имеют резкие изменения траектории. Построим вертикальные линии, где произошли потенциальные точки изменения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674db0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig = f.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), f, final_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1de37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.changepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00716e",
   "metadata": {},
   "source": [
    "Выгружаем прогноз в эксель. Спрогнозированное значение лежит в столбце yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3978c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forecast.to_excel(\"./app_forecast.xlsx\", sheet_name='Data', index=False, encoding=\"cp1251\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
